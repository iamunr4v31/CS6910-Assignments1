{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 10.7 MB/s eta 0:00:00\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.10.0-cp310-cp310-win_amd64.whl (42.5 MB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.24.2-cp310-cp310-win_amd64.whl (14.8 MB)\n",
      "Collecting jax\n",
      "  Downloading jax-0.4.3.tar.gz (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 15.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.13.10-py3-none-any.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 15.6 MB/s eta 0:00:00\n",
      "Collecting opt_einsum\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.5/65.5 kB ? eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\ashwi\\miniconda3\\envs\\dl_class\\lib\\site-packages (from wandb) (65.6.3)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\ashwi\\miniconda3\\envs\\dl_class\\lib\\site-packages (from wandb) (5.9.0)\n",
      "Collecting appdirs>=1.4.3\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting PyYAML\n",
      "  Using cached PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "Collecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.30-py3-none-any.whl (184 kB)\n",
      "     -------------------------------------- 184.0/184.0 kB 3.7 MB/s eta 0:00:00\n",
      "Collecting Click!=8.0.0,>=7.0\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "     ---------------------------------------- 96.6/96.6 kB 5.8 MB/s eta 0:00:00\n",
      "Collecting requests<3,>=2.0.0\n",
      "  Using cached requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting protobuf!=4.21.0,<5,>=3.19.0\n",
      "  Downloading protobuf-4.21.12-cp310-abi3-win_amd64.whl (527 kB)\n",
      "     -------------------------------------- 527.0/527.0 kB 5.5 MB/s eta 0:00:00\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.15.0-py2.py3-none-any.whl (181 kB)\n",
      "     -------------------------------------- 181.3/181.3 kB 5.3 MB/s eta 0:00:00\n",
      "Collecting setproctitle\n",
      "  Downloading setproctitle-1.3.2-cp310-cp310-win_amd64.whl (11 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\ashwi\\miniconda3\\envs\\dl_class\\lib\\site-packages (from Click!=8.0.0,>=7.0->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\ashwi\\miniconda3\\envs\\dl_class\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.7/62.7 kB 3.3 MB/s eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ashwi\\miniconda3\\envs\\dl_class\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.0.1-cp310-cp310-win_amd64.whl (96 kB)\n",
      "     ---------------------------------------- 96.5/96.5 kB 5.7 MB/s eta 0:00:00\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: jax, pathtools\n",
      "  Building wheel for jax (setup.py): started\n",
      "  Building wheel for jax (setup.py): finished with status 'done'\n",
      "  Created wheel for jax: filename=jax-0.4.3-py3-none-any.whl size=1384892 sha256=131c798bf81748b2930ff20618842e21c00da1c2a49d9ab31840ad360718e65f\n",
      "  Stored in directory: c:\\users\\ashwi\\appdata\\local\\pip\\cache\\wheels\\a4\\f9\\a7\\c78fd5f621d8cb0dc98e1f54266dcc51eabed7cf5fd20203f8\n",
      "  Building wheel for pathtools (setup.py): started\n",
      "  Building wheel for pathtools (setup.py): finished with status 'done'\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8792 sha256=c56875670ce410cdaa149eaa8e4ce2aac4ffd096ad141e53de17f94d03a42e5c\n",
      "  Stored in directory: c:\\users\\ashwi\\appdata\\local\\pip\\cache\\wheels\\44\\1b\\54\\249c94316d4e1030e2d0683fba1d8ea06197de866f5a4de738\n",
      "Successfully built jax pathtools\n",
      "Installing collected packages: pathtools, charset-normalizer, appdirs, urllib3, smmap, setproctitle, PyYAML, protobuf, numpy, keras, idna, docker-pycreds, Click, sentry-sdk, scipy, requests, opt_einsum, gitdb, jax, GitPython, wandb\n",
      "Successfully installed Click-8.1.3 GitPython-3.1.30 PyYAML-6.0 appdirs-1.4.4 charset-normalizer-3.0.1 docker-pycreds-0.4.0 gitdb-4.0.10 idna-3.4 jax-0.4.3 keras-2.11.0 numpy-1.24.2 opt_einsum-3.3.0 pathtools-0.1.2 protobuf-4.21.12 requests-2.28.2 scipy-1.10.0 sentry-sdk-1.15.0 setproctitle-1.3.2 smmap-5.0.0 urllib3-1.26.14 wandb-0.13.10\n"
     ]
    }
   ],
   "source": [
    "!pip install keras scipy numpy wandb "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.reshape(x_train.shape[0], -1).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class Module(ABC):\n",
    "    \n",
    "    @abstractmethod\n",
    "    def forward(self, *args, **kwargs):\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return self.__dict__\n",
    "\n",
    "class WsAndBs:\n",
    "    def __init__(self, out_size, in_size=1, type=\"Zero\") -> None:\n",
    "        self.value = self.initialize_weights((out_size, in_size), type)\n",
    "        self.grad = np.zeros_like(self.value)\n",
    "    \n",
    "    def initialize_weights(self, shape: tuple, type: str=\"Zero\") -> np.ndarray:\n",
    "        '''\n",
    "            Initialize weights of shape: (shape) with type: type strategy\n",
    "        '''\n",
    "        if type == \"Zero\":\n",
    "            return np.zeros(shape)\n",
    "        elif type == \"Xavier\":\n",
    "            raise NotImplementedError()\n",
    "        elif type == \"Random\":\n",
    "            return np.random.rand(shape)\n",
    "        else:\n",
    "            raise KeyError(\"Incorrect option for weight initialization strategy\")\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        self.grad = np.zeros_like(self.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear/Dense/Fully-Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, in_size: int, out_size: int, type=\"Zero\"):\n",
    "        '''\n",
    "            in_size: int -> Number of input units\n",
    "            out_size: int -> Number of output units\n",
    "            type: str -> \"Zero\" initialization or \"Xavier\" Initialization or \"Random\" Initialization\n",
    "        '''\n",
    "        self.Weights = WsAndBs(in_size, out_size, type)\n",
    "        self.bias = WsAndBs(out_size, 1, type)\n",
    "    \n",
    "    def __call__(self, x: np.ndarray) -> np.ndarray:\n",
    "        '''\n",
    "            x -> pass the numpy ndarray into the linear layer (out_size, x.shape[1])\n",
    "        '''\n",
    "        return self.Weights.value.T @ x + self.bias.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Weights': <__main__.WsAndBs at 0x25b4b5a98a0>,\n",
       " 'bias': <__main__.WsAndBs at 0x25b4b5a9b10>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll = Linear(2, 4, type=\"Zero\")\n",
    "vars(ll)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def __call__(self, x) -> np.ndarray:\n",
    "        baseline = np.zeros_like(x)\n",
    "        return np.maximum(x, baseline)\n",
    "    \n",
    "    def diff(self, x) -> np.ndarray:\n",
    "        return (x > 0).astype(int)\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self, scaler: int=1) -> None:\n",
    "        self.scaler = scaler\n",
    "    \n",
    "    def __call__(self, x: np.ndarray) -> np.ndarray:\n",
    "        sig = 1 / (1 + np.exp(-x))\n",
    "        return self.scaler * sig\n",
    "    \n",
    "    def diff(self, x) -> np.ndarray:\n",
    "        return self(x) * (1 - self(x))\n",
    "\n",
    "class Tanh:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, x: np.ndarray) -> np.ndarray:\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def diff(self, x) -> np.ndarray:\n",
    "        return 1 - self(x) ** 2\n",
    "\n",
    "class Softmax:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, x: np.ndarray) -> np.ndarray:\n",
    "        return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "    \n",
    "    def diff(self, x):\n",
    "        z = self(x)\n",
    "        return - np.outer(z, z) + np.diag(z.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Module):\n",
    "    def __init__(self) -> None:\n",
    "        self.layers = [\n",
    "            Linear(28*28, 1024), \n",
    "            Linear(1024, 512), \n",
    "            Linear(512, 256), \n",
    "            Linear(256, 10)\n",
    "            ]\n",
    "        self.relu = ReLU()\n",
    "        self.softmax = Softmax()\n",
    "        self.call_stack = []\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = self.relu(layer(x))\n",
    "            self.call_stack.append(self.relu)\n",
    "        x = self.softmax(self.layers[-1](x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7569003  0.49460604 0.36379068 ... 0.2674479  0.35733391 0.39038585]\n",
      " [0.26653186 0.07122563 0.48168974 ... 0.75514762 0.28510256 0.14774531]\n",
      " [0.22099282 0.35252487 0.22843665 ... 0.60700402 0.57776822 0.73806321]\n",
      " [0.23161329 0.20282435 0.88226183 ... 0.04563657 0.62501459 0.7204265 ]\n",
      " [0.90522623 0.45532616 0.34859206 ... 0.94351581 0.98118539 0.02678171]\n",
      " [0.46206164 0.05355742 0.69603832 ... 0.70005124 0.41965368 0.1458147 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(6, 28*28)\n",
    "print(x)\n",
    "model = Model()\n",
    "model.forward(x.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.call_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSELoss:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, y_pred, y_hat):\n",
    "        return np.mean((y_pred - y_hat) ** 2)\n",
    "    \n",
    "    def diff(self, y_pred, y_hat):\n",
    "        return  - np.mean((y_pred - y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MSELoss.__init__() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m])\n\u001b[0;32m      2\u001b[0m arr1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m loss \u001b[39m=\u001b[39m MSELoss()\n\u001b[0;32m      4\u001b[0m loss(arr, arr1)\n",
      "\u001b[1;31mTypeError\u001b[0m: MSELoss.__init__() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "arr = np.array([1, 2, 3, 2, 1, 2])\n",
    "arr1 = np.array([1, 2, 2, 1, 2, 3])\n",
    "loss = MSELoss()\n",
    "loss(arr, arr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5075078313266619"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.sum()/arr.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58023105, 0.54061111, 0.40168134])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.mean(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ebf2a3bacc3ce7beb8d8fb11b6ad33ab3ec68bc06abec3dda6ef36650034ef52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
